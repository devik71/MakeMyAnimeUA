#!/usr/bin/env python3
"""
üé¨ MakeMyAnimeUA ‚Äî –ì–æ–ª–æ–≤–Ω–∏–π –≤–µ–±-—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –ø–µ—Ä–µ–∫–ª–∞–¥—É —Å—É–±—Ç–∏—Ç—Ä—ñ–≤
"""

import os
import sys
import json
import hashlib
import subprocess
import re
from pathlib import Path
from flask import Flask, render_template, request, jsonify, redirect, url_for, send_file, session
from werkzeug.utils import secure_filename
import uuid
from datetime import datetime
import threading
import time

# –î–æ–¥–∞—î–º–æ —à–ª—è—Ö –¥–æ –º–æ–¥—É–ª—ñ–≤
sys.path.append(str(Path(__file__).resolve().parent))
from magi_pipeline.utils.balthasar import Balthasar
from magi_pipeline.utils.melchior import Melchior
from magi_pipeline.utils.caspar import Caspar
from magi_pipeline.utils.external_subs import find_external_subtitles, get_subtitle_preview

app = Flask(__name__)
app.secret_key = 'magi_pipeline_secret_key_2024'

# –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è
UPLOAD_FOLDER = Path("uploads")
OUTPUT_FOLDER = Path("output") 
TEMP_AUDIO_FOLDER = Path("temp_audio")
ALLOWED_VIDEO_EXTENSIONS = {'mp4', 'mkv', 'avi', 'mov'}
ALLOWED_SUBTITLE_EXTENSIONS = {'srt', 'ass', 'ssa', 'vtt'}

# –°—Ç–≤–æ—Ä—é—î–º–æ –Ω–µ–æ–±—Ö—ñ–¥–Ω—ñ –ø–∞–ø–∫–∏
for folder in [UPLOAD_FOLDER, OUTPUT_FOLDER, TEMP_AUDIO_FOLDER]:
    folder.mkdir(exist_ok=True)

# –ì–ª–æ–±–∞–ª—å–Ω–∏–π —Å–ª–æ–≤–Ω–∏–∫ –¥–ª—è –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è —Å—Ç–∞–Ω—É —Å–µ—Å—ñ–π
processing_sessions = {}

def allowed_file(filename, extensions):
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î —á–∏ –¥–æ–∑–≤–æ–ª–µ–Ω–æ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è —Ñ–∞–π–ª—É"""
    if not filename or '.' not in filename:
        return False
    return filename.rsplit('.', 1)[1].lower() in extensions

def is_valid_video_file(file_path):
    """–î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —Ñ–∞–π–ª —î –≤–∞–ª—ñ–¥–Ω–∏–º –≤—ñ–¥–µ–æ"""
    try:
        # –®–≤–∏–¥–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–µ—Ä–µ–∑ ffprobe
        probe = subprocess.run([
            "ffprobe", "-v", "error", "-select_streams", "v:0", 
            "-show_entries", "stream=codec_type", "-of", "csv=p=0", str(file_path)
        ], capture_output=True, text=True, timeout=10)
        
        return probe.returncode == 0 and "video" in probe.stdout
    except Exception:
        return False

def get_file_hash(path):
    """–ì–µ–Ω–µ—Ä—É—î —Ö–µ—à —Ñ–∞–π–ª—É –¥–ª—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó"""
    h = hashlib.sha256()
    with open(path, "rb") as f:
        while True:
            chunk = f.read(8192)
            if not chunk:
                break
            h.update(chunk)
    return h.hexdigest()

def analyze_video(video_path):
    """–ê–Ω–∞–ª—ñ–∑—É—î –≤—ñ–¥–µ–æ —Ñ–∞–π–ª - –∞—É–¥—ñ–æ –¥–æ—Ä—ñ–∂–∫–∏ —Ç–∞ —Å—É–±—Ç–∏—Ç—Ä–∏"""
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ —Ñ–∞–π–ª —ñ—Å–Ω—É—î
        if not video_path.exists():
            return {"error": "–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"}
            
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ ffprobe –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
        probe = subprocess.run([
            "ffprobe", "-v", "quiet", "-print_format", "json", "-show_streams", str(video_path)
        ], capture_output=True, text=True)
        
        if probe.returncode != 0:
            # –î–µ—Ç–∞–ª—å–Ω—ñ—à–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É
            error_msg = probe.stderr if probe.stderr else "–ù–µ–≤–∞–ª—ñ–¥–Ω–∏–π –≤—ñ–¥–µ–æ —Ñ–∞–π–ª"
            return {"error": f"–ü–æ–º–∏–ª–∫–∞ ffprobe: {error_msg}"}
        
        if not probe.stdout.strip():
            return {"error": "ffprobe –Ω–µ –ø–æ–≤–µ—Ä–Ω—É–≤ –¥–∞–Ω–∏—Ö - –º–æ–∂–ª–∏–≤–æ —Ñ–∞–π–ª –ø–æ—à–∫–æ–¥–∂–µ–Ω–∏–π"}
            
        streams_data = json.loads(probe.stdout)
        audio_streams = []
        subtitle_streams = []
        
        for stream in streams_data.get("streams", []):
            if stream["codec_type"] == "audio":
                audio_streams.append({
                    "index": stream["index"],
                    "codec": stream.get("codec_name", "unknown"),
                    "channels": stream.get("channels", 0),
                    "language": stream.get("tags", {}).get("language", "unknown"),
                    "title": stream.get("tags", {}).get("title", "")
                })
            elif stream["codec_type"] == "subtitle":
                subtitle_streams.append({
                    "index": stream["index"],
                    "codec": stream.get("codec_name", "unknown"),
                    "language": stream.get("tags", {}).get("language", "unknown"),
                    "title": stream.get("tags", {}).get("title", "")
                })
        
        # –®—É–∫–∞—î–º–æ –∑–æ–≤–Ω—ñ—à–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏
        external_subs = find_external_subtitles(video_path, [video_path.parent])
        
        return {
            "audio_streams": audio_streams,
            "subtitle_streams": subtitle_streams,
            "external_subtitles": external_subs,
            "video_info": {
                "filename": video_path.name,
                "size": video_path.stat().st_size,
                "hash": get_file_hash(video_path)
            }
        }
    except Exception as e:
        return {"error": f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É –≤—ñ–¥–µ–æ: {str(e)}"}

def get_available_whisper_models():
    """–ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π Whisper"""
    import torch
    
    models = [
        {"name": "tiny", "size": "39 MB", "vram": "~1 GB", "quality": "–ù–∏–∑—å–∫–∞", "speed": "–î—É–∂–µ —à–≤–∏–¥–∫–∞"},
        {"name": "base", "size": "74 MB", "vram": "~1 GB", "quality": "–•–æ—Ä–æ—à–∞", "speed": "–®–≤–∏–¥–∫–∞"},
        {"name": "small", "size": "244 MB", "vram": "~2 GB", "quality": "–ö—Ä–∞—â–∞", "speed": "–°–µ—Ä–µ–¥–Ω—è"},
        {"name": "medium", "size": "769 MB", "vram": "~4 GB", "quality": "–í—ñ–¥–º—ñ–Ω–Ω–∞", "speed": "–ü–æ–≤—ñ–ª—å–Ω–∞"},
        {"name": "large", "size": "1550 MB", "vram": "~8 GB", "quality": "–ù–∞–π–∫—Ä–∞—â–∞", "speed": "–î—É–∂–µ –ø–æ–≤—ñ–ª—å–Ω–∞"}
    ]
    
    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –¥–æ—Å—Ç—É–ø–Ω—ñ—Å—Ç—å GPU
    gpu_available = torch.cuda.is_available()
    if gpu_available:
        gpu_memory = torch.cuda.get_device_properties(0).total_memory // (1024**3)  # GB
        recommended = "large" if gpu_memory >= 8 else "medium" if gpu_memory >= 4 else "small" if gpu_memory >= 2 else "base"
    else:
        recommended = "base"
        gpu_memory = 0
    
    return {
        "models": models,
        "gpu_available": gpu_available,
        "gpu_memory": gpu_memory,
        "recommended": recommended
    }

def get_available_subtitle_styles():
    """–ü–æ–≤–µ—Ä—Ç–∞—î —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω–∏—Ö —Å—Ç–∏–ª—ñ–≤ —Å—É–±—Ç–∏—Ç—Ä—ñ–≤"""
    styles_dir = Path("magi_pipeline/ass_generator_module/styles")
    styles = []
    
    if styles_dir.exists():
        for style_file in styles_dir.glob("*.ass"):
            styles.append({
                "filename": style_file.name,
                "name": style_file.stem,
                "path": str(style_file)
            })
    
    return styles

@app.route('/')
def index():
    """–ì–æ–ª–æ–≤–Ω–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞"""
    import time
    session_id = request.args.get('session')
    
    # –Ø–∫—â–æ –ø–µ—Ä–µ–¥–∞–Ω–æ session_id, –≤—ñ–¥–Ω–æ–≤–ª—é—î–º–æ —Å–µ—Å—ñ—é
    if session_id and session_id in processing_sessions:
        session['session_id'] = session_id
    
    return render_template('main_pipeline.html', 
                         timestamp=int(time.time()),
                         session_id=session_id)

@app.route('/test')
def test_upload():
    """–¢–µ—Å—Ç–æ–≤–∞ —Å—Ç–æ—Ä—ñ–Ω–∫–∞ –¥–ª—è –¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è"""
    with open('test_upload.html', 'r') as f:
        return f.read()

@app.route('/upload_video', methods=['POST'])
def upload_video():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤—ñ–¥–µ–æ —Ñ–∞–π–ª—É"""
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –Ω–∞—è–≤–Ω—ñ—Å—Ç—å —Ñ–∞–π–ª—É
        if 'video' not in request.files:
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤–∏–±—Ä–∞–Ω–æ"}), 400
        
        file = request.files['video']
        if file.filename == '':
            return jsonify({"error": "–§–∞–π–ª –Ω–µ –≤–∏–±—Ä–∞–Ω–æ"}), 400
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ä–æ–∑–º—ñ—Ä —Ñ–∞–π–ª—É (max 2GB)
        if hasattr(file, 'content_length') and file.content_length > 2 * 1024 * 1024 * 1024:
            return jsonify({"error": "–§–∞–π–ª –∑–∞–Ω–∞–¥—Ç–æ –≤–µ–ª–∏–∫–∏–π (–º–∞–∫—Å–∏–º—É–º 2GB)"}), 400
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É
        if not file or not allowed_file(file.filename, ALLOWED_VIDEO_EXTENSIONS):
            return jsonify({"error": f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª—É. –ü—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω—ñ: {', '.join(ALLOWED_VIDEO_EXTENSIONS)}"}), 400
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—É —Å–µ—Å—ñ—é
        session_id = str(uuid.uuid4())
        session['session_id'] = session_id
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É uploads —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î
        UPLOAD_FOLDER.mkdir(exist_ok=True)
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª
        filename = secure_filename(file.filename)
        video_path = UPLOAD_FOLDER / f"{session_id}_{filename}"
        
        print(f"–ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª: {video_path}")
        file.save(video_path)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —â–æ —Ñ–∞–π–ª –∑–±–µ—Ä–µ–∂–µ–Ω–æ
        if not video_path.exists():
            return jsonify({"error": "–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É"}), 500
        
        print(f"–§–∞–π–ª –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ. –†–æ–∑–º—ñ—Ä: {video_path.stat().st_size} –±–∞–π—Ç")
        
        # –î–æ–¥–∞—Ç–∫–æ–≤–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —Ñ–∞–π–ª —î –≤–∞–ª—ñ–¥–Ω–∏–º –≤—ñ–¥–µ–æ
        print("–ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –≤–∞–ª—ñ–¥–Ω—ñ—Å—Ç—å –≤—ñ–¥–µ–æ —Ñ–∞–π–ª—É...")
        if not is_valid_video_file(video_path):
            # –í–∏–¥–∞–ª—è—î–º–æ –Ω–µ–≤–∞–ª—ñ–¥–Ω–∏–π —Ñ–∞–π–ª
            video_path.unlink(missing_ok=True)
            return jsonify({"error": "–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Ñ–∞–π–ª –Ω–µ —î –≤–∞–ª—ñ–¥–Ω–∏–º –≤—ñ–¥–µ–æ —Ñ–∞–π–ª–æ–º. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ç–∞ —Ü—ñ–ª—ñ—Å–Ω—ñ—Å—Ç—å —Ñ–∞–π–ª—É."}), 400
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –≤—ñ–¥–µ–æ
        print("–ü–æ—á–∏–Ω–∞—î–º–æ –∞–Ω–∞–ª—ñ–∑ –≤—ñ–¥–µ–æ...")
        analysis = analyze_video(video_path)
        print(f"–ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {analysis}")
        
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ —Å–µ—Å—ñ—é
        processing_sessions[session_id] = {
            "video_path": str(video_path),
            "analysis": analysis,
            "created_at": datetime.now().isoformat(),
            "status": "analyzed"
        }
        
        return jsonify({
            "session_id": session_id,
            "analysis": analysis,
            "whisper_models": get_available_whisper_models(),
            "subtitle_styles": get_available_subtitle_styles()
        })
        
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"–í–Ω—É—Ç—Ä—ñ—à–Ω—è –ø–æ–º–∏–ª–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}"}), 500

@app.route('/start_processing', methods=['POST'])
def start_processing():
    """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—É –æ–±—Ä–æ–±–∫–∏"""
    session_id = session.get('session_id')
    if not session_id or session_id not in processing_sessions:
        return jsonify({"error": "–°–µ—Å—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"})
    
    config = request.get_json()
    session_data = processing_sessions[session_id]
    session_data['config'] = config
    session_data['status'] = 'processing'
    session_data['progress'] = {"step": "starting", "percent": 0, "message": "–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è..."}
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –æ–±—Ä–æ–±–∫—É –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
    thread = threading.Thread(target=process_video_async, args=(session_id,))
    thread.daemon = True
    thread.start()
    
    return jsonify({"status": "started"})

def process_video_async(session_id):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –≤—ñ–¥–µ–æ —á–µ—Ä–µ–∑ —Ç–µ—Ä–º—ñ–Ω–∞–ª—å–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω"""
    try:
        session_data = processing_sessions[session_id]
        config = session_data['config']
        video_path = Path(session_data['video_path'])
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–Ω—Ñ—ñ–≥-—Ñ–∞–π–ª –¥–ª—è —Ç–µ—Ä–º—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω—É
        config_path = TEMP_AUDIO_FOLDER / f"{session_id}_config.json"
        
        pipeline_config = {
            "session_id": session_id,
            "video_path": str(video_path),
            "output_dir": str(OUTPUT_FOLDER),
            "temp_dir": str(TEMP_AUDIO_FOLDER),
            "translation_engine": config.get('translation_engine', 'helsinki'),
            "source_language": config.get('source_language', 'ru'),
            "target_language": config.get('target_language', 'uk'),
            "whisper_model": config.get('whisper_model', 'base'),
            "use_gpu": config.get('use_gpu', True),
            "subtitle_style": config.get('subtitle_style', 'magi_pipeline/ass_generator_module/styles/Dialogue.ass'),
            "deepl_api_key": config.get('deepl_api_key'),
            "source_type": config.get('source_type', 'transcribe'),
            "subtitle_stream_index": config.get('subtitle_stream_index'),
            "external_subtitle_path": config.get('external_subtitle_path'),
            "web_interface": True
        }
        
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(pipeline_config, f, ensure_ascii=False, indent=2)
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ –ª–æ–≥-—Ñ–∞–π–ª –¥–ª—è –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É
        log_path = TEMP_AUDIO_FOLDER / f"{session_id}_pipeline.log"
        status_path = TEMP_AUDIO_FOLDER / f"{session_id}_status.json"
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ —Ç–µ—Ä–º—ñ–Ω–∞–ª—å–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω
        session_data['progress'] = {"step": "starting_pipeline", "percent": 5, "message": "–ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω—É..."}
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –ø–∞–π–ø–ª–∞–π–Ω —É —Ñ–æ–Ω–æ–≤–æ–º—É —Ä–µ–∂–∏–º—ñ
        import subprocess
        import sys
        
        cmd = [
            sys.executable, 
            "scripts/run_pipeline.py",
            "--config", str(config_path),
            "--session", session_id,
            "--log", str(log_path),
            "--status", str(status_path)
        ]
        
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=str(Path(__file__).parent)
        )
        
        session_data['pipeline_process'] = process
        session_data['log_path'] = str(log_path)
        session_data['status_path'] = str(status_path)
        
        # –ó–∞–ø—É—Å–∫–∞—î–º–æ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—É
        thread = threading.Thread(target=monitor_pipeline_progress, args=(session_id,))
        thread.daemon = True
        thread.start()
        
    except Exception as e:
        session_data['progress'] = {"step": "error", "percent": 0, "message": f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–ø—É—Å–∫—É: {str(e)}"}
        session_data['status'] = 'error'

def monitor_pipeline_progress(session_id):
    """–ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—É —Ç–µ—Ä–º—ñ–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω—É"""
    try:
        session_data = processing_sessions[session_id]
        status_path = Path(session_data['status_path'])
        log_path = Path(session_data['log_path'])
        
        while True:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Å—Ç–∞—Ç—É—Å-—Ñ–∞–π–ª
            if status_path.exists():
                try:
                    with open(status_path, 'r', encoding='utf-8') as f:
                        status_data = json.load(f)
                    
                    session_data['progress'] = status_data.get('progress', session_data['progress'])
                    session_data['status'] = status_data.get('status', session_data['status'])
                    
                    # –Ø–∫—â–æ –ø–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–∏–≤—Å—è
                    if status_data.get('status') in ['complete', 'error', 'translation_ready']:
                        if status_data.get('status') == 'translation_ready':
                            session_data['translation_path'] = status_data.get('translation_path')
                        elif status_data.get('status') == 'complete':
                            session_data['final_ass_path'] = status_data.get('final_ass_path')
                        break
                        
                except Exception as e:
                    print(f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è —Å—Ç–∞—Ç—É—Å—É: {e}")
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —á–∏ –ø—Ä–æ—Ü–µ—Å —â–µ –ø—Ä–∞—Ü—é—î
            process = session_data.get('pipeline_process')
            if process and process.poll() is not None:
                # –ü—Ä–æ—Ü–µ—Å –∑–∞–≤–µ—Ä—à–∏–≤—Å—è
                if process.returncode == 0:
                    session_data['progress'] = {"step": "complete", "percent": 100, "message": "–ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–µ–Ω–æ"}
                    session_data['status'] = 'complete'
                else:
                    stdout, stderr = process.communicate()
                    error_msg = stderr if stderr else "–ù–µ–≤—ñ–¥–æ–º–∞ –ø–æ–º–∏–ª–∫–∞"
                    session_data['progress'] = {"step": "error", "percent": 0, "message": f"–ü–æ–º–∏–ª–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω—É: {error_msg}"}
                    session_data['status'] = 'error'
                break
            
            time.sleep(2)  # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–∂–Ω—ñ 2 —Å–µ–∫—É–Ω–¥–∏
            
    except Exception as e:
        session_data['progress'] = {"step": "error", "percent": 0, "message": f"–ü–æ–º–∏–ª–∫–∞ –º–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥—É: {str(e)}"}
        session_data['status'] = 'error'

def parse_srt(path):
    """–ü–∞—Ä—Å–∏–Ω–≥ SRT —Ñ–∞–π–ª—É"""
    subs = []
    with open(path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    pattern = re.compile(r'(\d+)\s+([\d:,]+)\s+-->\s+([\d:,]+)\s+([\s\S]*?)(?=\n\d+\n|\Z)', re.MULTILINE)
    for match in pattern.finditer(content):
        start = match.group(2).replace(',', '.')
        end = match.group(3).replace(',', '.')
        text = match.group(4).replace('\n', ' ').strip()
        
        def to_seconds(t):
            h, m, s = t.split(':')
            s, ms = s.split('.') if '.' in s else (s, '0')
            return int(h)*3600 + int(m)*60 + int(s) + int(ms.ljust(3, '0')[:3])/1000
        
        subs.append({
            'start': to_seconds(start),
            'end': to_seconds(end),
            'text': text
        })
    
    return {'segments': subs}

def parse_ass(path):
    """–ü–∞—Ä—Å–∏–Ω–≥ ASS —Ñ–∞–π–ª—É"""
    subs = []
    with open(path, 'r', encoding='utf-8') as f:
        for line in f:
            if line.startswith('Dialogue:'):
                parts = line.strip().split(',', 9)
                if len(parts) >= 10:
                    start = parts[1]
                    end = parts[2]
                    text = parts[9].replace('\\N', ' ').replace('\n', ' ').strip()
                    
                    def ass_time_to_seconds(t):
                        h, m, s = t.split(':')
                        s, cs = s.split('.') if '.' in s else (s, '0')
                        return int(h)*3600 + int(m)*60 + int(s) + int(cs)/100
                    
                    subs.append({
                        'start': ass_time_to_seconds(start),
                        'end': ass_time_to_seconds(end),
                        'text': text
                    })
    
    return {'segments': subs}

@app.route('/get_progress')
def get_progress():
    """–û—Ç—Ä–∏–º–∞–Ω–Ω—è –ø—Ä–æ–≥—Ä–µ—Å—É –æ–±—Ä–æ–±–∫–∏"""
    session_id = session.get('session_id')
    if not session_id or session_id not in processing_sessions:
        return jsonify({"error": "–°–µ—Å—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"})
    
    session_data = processing_sessions[session_id]
    return jsonify({
        "status": session_data.get('status', 'unknown'),
        "progress": session_data.get('progress', {})
    })

@app.route('/edit_translation')
def edit_translation():
    """–ü–µ—Ä–µ—Ö—ñ–¥ –¥–æ —Ä–µ–¥–∞–∫—Ç–æ—Ä–∞ –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
    session_id = session.get('session_id')
    if not session_id or session_id not in processing_sessions:
        return redirect(url_for('index'))
    
    session_data = processing_sessions[session_id]
    if session_data.get('status') != 'translation_ready':
        return redirect(url_for('index'))
    
    # –ü–µ—Ä–µ–¥–∞—î–º–æ session_id —Ä–µ–¥–∞–∫—Ç–æ—Ä—É
    return redirect(f"/editor?session={session_id}")

@app.route('/editor')
def translation_editor():
    """–†–µ–¥–∞–∫—Ç–æ—Ä –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
    import time
    session_id = request.args.get('session')
    
    if not session_id or session_id not in processing_sessions:
        return redirect(url_for('index'))
    
    session_data = processing_sessions[session_id]
    translation_path = session_data.get('translation_path')
    
    if not translation_path or not Path(translation_path).exists():
        return redirect(url_for('index'))
    
    return render_template('translation_editor.html', 
                         session_id=session_id, 
                         timestamp=int(time.time()))

@app.route('/api/translation/<session_id>')
def get_translation_data(session_id):
    """API –¥–ª—è –æ—Ç—Ä–∏–º–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
    if session_id not in processing_sessions:
        return jsonify({"error": "–°–µ—Å—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"}), 404
    
    session_data = processing_sessions[session_id]
    translation_path = session_data.get('translation_path')
    
    if not translation_path or not Path(translation_path).exists():
        return jsonify({"error": "–§–∞–π–ª –ø–µ—Ä–µ–∫–ª–∞–¥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"}), 404
    
    try:
        with open(translation_path, 'r', encoding='utf-8') as f:
            translation_data = json.load(f)
        return jsonify(translation_data)
    except Exception as e:
        return jsonify({"error": f"–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è —Ñ–∞–π–ª—É: {str(e)}"}), 500

@app.route('/api/translation/<session_id>', methods=['POST'])
def save_translation_data(session_id):
    """API –¥–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–º—ñ–Ω –ø–µ—Ä–µ–∫–ª–∞–¥—É"""
    if session_id not in processing_sessions:
        return jsonify({"error": "–°–µ—Å—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"}), 404
    
    session_data = processing_sessions[session_id]
    translation_path = session_data.get('translation_path')
    
    if not translation_path:
        return jsonify({"error": "–§–∞–π–ª –ø–µ—Ä–µ–∫–ª–∞–¥—É –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"}), 404
    
    try:
        data = request.get_json()
        if not data or 'segments' not in data:
            return jsonify({"error": "–ù–µ–≤—ñ—Ä–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–∏—Ö"}), 400
        
        # –û–Ω–æ–≤–ª—é—î–º–æ timestamp
        data['meta']['updated_at'] = datetime.now().isoformat()
        
        with open(translation_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        return jsonify({"success": True, "message": "–ü–µ—Ä–µ–∫–ª–∞–¥ –∑–±–µ—Ä–µ–∂–µ–Ω–æ"})
    except Exception as e:
        return jsonify({"error": f"–ü–æ–º–∏–ª–∫–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è: {str(e)}"}), 500

@app.route('/continue_processing', methods=['POST'])
def continue_processing():
    """–ü—Ä–æ–¥–æ–≤–∂–µ–Ω–Ω—è –æ–±—Ä–æ–±–∫–∏ –ø—ñ—Å–ª—è —Ä–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è (–∞–±–æ –±–µ–∑ –Ω—å–æ–≥–æ)"""
    session_id = session.get('session_id')
    if not session_id or session_id not in processing_sessions:
        return jsonify({"error": "–°–µ—Å—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"})
    
    session_data = processing_sessions[session_id]
    config = session_data['config']
    
    # –ó–∞–ø—É—Å–∫–∞—î–º–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é ASS –≤ –æ–∫—Ä–µ–º–æ–º—É –ø–æ—Ç–æ—Ü—ñ
    thread = threading.Thread(target=generate_final_subtitles_async, args=(session_id,))
    thread.daemon = True
    thread.start()
    
    return jsonify({"status": "generating"})

def generate_final_subtitles_async(session_id):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ñ—ñ–Ω–∞–ª—å–Ω–∏—Ö —Å—É–±—Ç–∏—Ç—Ä—ñ–≤"""
    try:
        session_data = processing_sessions[session_id]
        config = session_data['config']
        
        session_data['progress'] = {"step": "ass_generation", "percent": 95, "message": "–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è ASS..."}
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø–µ—Ä–µ–∫–ª–∞–¥–µ–Ω—ñ —Å—É–±—Ç–∏—Ç—Ä–∏
        translation_path = session_data['translation_path']
        with open(translation_path, 'r', encoding='utf-8') as f:
            translation_data = json.load(f)
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–ª—è—î–º–æ –¥–∞–Ω—ñ –¥–ª—è ASS –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        subs = []
        for segment in translation_data['segments']:
            subs.append({
                "start": segment["start"],
                "end": segment["end"],
                "text": segment["translated"]
            })
        
        # –ì–µ–Ω–µ—Ä—É—î–º–æ ASS —Ñ–∞–π–ª
        video_name = Path(session_data['video_path']).stem
        output_path = OUTPUT_FOLDER / f"{video_name}.ass"
        
        style_path = config.get('subtitle_style', 'magi_pipeline/ass_generator_module/styles/Dialogue.ass')
        
        Caspar.generate_subtitles(
            subs=subs,
            output_path=str(output_path),
            style_path=style_path
        )
        
        session_data['final_ass_path'] = str(output_path)
        session_data['progress'] = {"step": "complete", "percent": 100, "message": "–ì–æ—Ç–æ–≤–æ!"}
        session_data['status'] = 'complete'
        
    except Exception as e:
        session_data['progress'] = {"step": "error", "percent": 0, "message": f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó: {str(e)}"}
        session_data['status'] = 'error'

@app.route('/download_subtitles')
def download_subtitles():
    """–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≥–æ—Ç–æ–≤–∏—Ö —Å—É–±—Ç–∏—Ç—Ä—ñ–≤"""
    session_id = session.get('session_id')
    if not session_id or session_id not in processing_sessions:
        return "–°–µ—Å—ñ—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞", 404
    
    session_data = processing_sessions[session_id]
    if 'final_ass_path' not in session_data:
        return "–§–∞–π–ª –Ω–µ –≥–æ—Ç–æ–≤–∏–π", 404
    
    return send_file(session_data['final_ass_path'], as_attachment=True)

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ MakeMyAnimeUA - –ì–æ–ª–æ–≤–Ω–∏–π –ø–∞–π–ø–ª–∞–π–Ω")
    print("üìç http://localhost:5001")
    app.run(debug=True, port=5001, host='0.0.0.0')